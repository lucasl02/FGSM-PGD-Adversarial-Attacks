{"cells":[{"cell_type":"markdown","metadata":{"id":"Whsg1XX_OZs6"},"source":["# Set up for dataset and model\n","\n","Package installation, loading, and dataloaders. There's also a resnet18 model defined."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"66CgRSqTns3o","outputId":"e0b8a291-cbd2-4110-c22d-8a452ace94ee","executionInfo":{"status":"ok","timestamp":1758323708192,"user_tz":300,"elapsed":19,"user":{"displayName":"Lucas Liu","userId":"15281844812703134281"}},"colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stdout","text":["/usr/bin/python3\n"]}],"source":["import sys\n","print(sys.executable)\n","import certifi, ssl\n","#ssl._create_default_https_context = ssl._create_unverified_context\n"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"R1domTvnONqD","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1758323826026,"user_tz":300,"elapsed":28374,"user":{"displayName":"Lucas Liu","userId":"15281844812703134281"}},"outputId":"aa700bd0-375b-4920-d73a-bba88d408df1"},"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 170M/170M [00:08<00:00, 19.4MB/s]\n"]},{"output_type":"stream","name":"stdout","text":["Device in use: cuda\n"]}],"source":["# Install dependencies (Colab already has torch/torchvision, but just in case)\n","!pip install torch torchvision tqdm matplotlib tensorboardX -q\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","import numpy as np\n","import time\n","import matplotlib.pyplot as plt\n","from tqdm import tqdm\n","from torchvision import datasets, transforms\n","\n","# Use GPU if available\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","batch_size = 64\n","\n","np.random.seed(42)\n","torch.manual_seed(42)\n","\n","# Dataloaders\n","train_dataset = datasets.CIFAR10(\n","    root=\"/content/cifar10_data\",\n","    train=True,\n","    download=True,\n","    transform=transforms.ToTensor()\n",")\n","test_dataset = datasets.CIFAR10(\n","    root=\"/content/cifar10_data\",\n","    train=False,\n","    download=True,\n","    transform=transforms.ToTensor()\n",")\n","\n","train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"c8L9Foo0ns3p","executionInfo":{"status":"ok","timestamp":1758323835558,"user_tz":300,"elapsed":108,"user":{"displayName":"Lucas Liu","userId":"15281844812703134281"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"60918e51-f906-45bf-f066-c17ee310d5ad"},"outputs":[{"output_type":"stream","name":"stdout","text":["Device in use: cuda\n"]}],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(f\"Device in use: {device}\")\n","\n","def tp_relu(x, delta=1.):\n","    ind1 = (x < -1. * delta).float()\n","    ind2 = (x > delta).float()\n","    return .5 * (x + delta) * (1 - ind1) * (1 - ind2) + x * ind2\n","\n","def tp_smoothed_relu(x, delta=1.):\n","    ind1 = (x < -1. * delta).float()\n","    ind2 = (x > delta).float()\n","    return (x + delta) ** 2 / (4 * delta) * (1 - ind1) * (1 - ind2) + x * ind2\n","\n","class Normalize(nn.Module):\n","    def __init__(self, mu, std):\n","        super(Normalize, self).__init__()\n","        self.mu, self.std = mu, std\n","\n","    def forward(self, x):\n","        return (x - self.mu.to(x.device)) / self.std.to(x.device)\n","\n","class IdentityLayer(nn.Module):\n","    def forward(self, inputs):\n","        return inputs\n","\n","class PreActBlock(nn.Module):\n","    expansion = 1\n","\n","    def __init__(self, in_planes, planes, bn, learnable_bn, stride=1, activation='relu'):\n","        super(PreActBlock, self).__init__()\n","        self.activation = activation\n","        self.bn1 = nn.BatchNorm2d(in_planes, affine=learnable_bn) if bn else IdentityLayer()\n","        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=not learnable_bn)\n","        self.bn2 = nn.BatchNorm2d(planes, affine=learnable_bn) if bn else IdentityLayer()\n","        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=not learnable_bn)\n","\n","        if stride != 1 or in_planes != self.expansion*planes:\n","            self.shortcut = nn.Sequential(\n","                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=not learnable_bn)\n","            )\n","\n","    def act_function(self, preact):\n","        if self.activation == 'relu':\n","            return F.relu(preact)\n","        elif self.activation[:6] == '3prelu':\n","            return tp_relu(preact, delta=float(self.activation.split('relu')[1]))\n","        elif self.activation[:8] == '3psmooth':\n","            return tp_smoothed_relu(preact, delta=float(self.activation.split('smooth')[1]))\n","        else:\n","            beta = int(self.activation.split('softplus')[1])\n","            return F.softplus(preact, beta=beta)\n","\n","    def forward(self, x):\n","        out = self.act_function(self.bn1(x))\n","        shortcut = self.shortcut(out) if hasattr(self, 'shortcut') else x\n","        out = self.conv1(out)\n","        out = self.conv2(self.act_function(self.bn2(out)))\n","        out += shortcut\n","        return out\n","\n","class PreActResNet(nn.Module):\n","    def __init__(self, block, num_blocks, n_cls, activation='relu', fts_before_bn=False, normal='none'):\n","        super(PreActResNet, self).__init__()\n","        self.bn = True\n","        self.learnable_bn = True\n","        self.in_planes = 64\n","        self.activation = activation\n","        self.fts_before_bn = fts_before_bn\n","\n","        if normal == 'cifar10':\n","            self.mu = torch.tensor((0.4914, 0.4822, 0.4465)).view(1, 3, 1, 1)\n","            self.std = torch.tensor((0.2471, 0.2435, 0.2616)).view(1, 3, 1, 1)\n","        else:\n","            self.mu = torch.tensor((0.0, 0.0, 0.0)).view(1, 3, 1, 1)\n","            self.std = torch.tensor((1.0, 1.0, 1.0)).view(1, 3, 1, 1)\n","            print('no input normalization')\n","\n","        self.normalize = Normalize(self.mu, self.std)\n","        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=not self.learnable_bn)\n","        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n","        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n","        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n","        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n","        self.bn = nn.BatchNorm2d(512 * block.expansion)\n","        self.linear = nn.Linear(512*block.expansion, n_cls)\n","\n","    def _make_layer(self, block, planes, num_blocks, stride):\n","        strides = [stride] + [1]*(num_blocks-1)\n","        layers = []\n","        for stride in strides:\n","            layers.append(block(self.in_planes, planes, self.bn, self.learnable_bn, stride, self.activation))\n","            self.in_planes = planes * block.expansion\n","        return nn.Sequential(*layers)\n","\n","    def forward(self, x, return_features=False):\n","        out = self.normalize(x)\n","        out = self.conv1(out)\n","        out = self.layer1(out)\n","        out = self.layer2(out)\n","        out = self.layer3(out)\n","        out = self.layer4(out)\n","        if return_features and self.fts_before_bn:\n","            return out.view(out.size(0), -1)\n","        out = F.relu(self.bn(out))\n","        if return_features:\n","            return out.view(out.size(0), -1)\n","        out = F.avg_pool2d(out, 4)\n","        out = out.view(out.size(0), -1)\n","        out = self.linear(out)\n","        return out\n","\n","def PreActResNet18(n_cls, activation='relu', fts_before_bn=False, normal='none'):\n","    return PreActResNet(PreActBlock, [2, 2, 2, 2], n_cls=n_cls,\n","                        activation=activation, fts_before_bn=fts_before_bn, normal=normal)"]},{"cell_type":"markdown","metadata":{"id":"NCmWfZHTO8Oo"},"source":["# Implement the Attacks\n","\n","Functions are given a simple useful signature that you can start with. Feel free to extend the signature as you see fit.\n","\n","You may find it useful to create a 'batched' version of PGD that you can use to create the adversarial attack."]},{"cell_type":"code","execution_count":6,"metadata":{"id":"EZjvA49yONqP","executionInfo":{"status":"ok","timestamp":1758323841925,"user_tz":300,"elapsed":15,"user":{"displayName":"Lucas Liu","userId":"15281844812703134281"}}},"outputs":[],"source":["def pgd_linf_untargeted(model, x, labels, k, eps, eps_step):\n","    model.eval()\n","    ce_loss = torch.nn.CrossEntropyLoss()\n","    adv_x = x.clone().detach()\n","    adv_x.requires_grad_(True)\n","    for _ in range(k):\n","        adv_x.requires_grad_(True)\n","        model.zero_grad()\n","        output = model(adv_x)\n","        # TODO: Calculate the loss\n","        loss = ce_loss(output, labels)\n","        loss.backward()\n","        # TODO: compute the adv_x\n","        grad = adv_x.grad\n","        adv_x = adv_x  + (eps_step * torch.sign(grad))\n","        # find delta, clamp with eps\n","        #linf so can check values individually\n","        # change has to be eps bubble at max: delta = [-eps, eps]\n","        delta = torch.clamp(adv_x - x, min = -eps, max= eps)\n","        # calmp to image domain: adv_x = [0,1]\n","        adv_x = torch.clamp(x + delta, min = 0.0, max = 1.0).detach().requires_grad_()\n","\n","    return adv_x"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"4MvpPvO-ns3p","executionInfo":{"status":"ok","timestamp":1758323843628,"user_tz":300,"elapsed":8,"user":{"displayName":"Lucas Liu","userId":"15281844812703134281"}}},"outputs":[],"source":["def pgd_l2_untargeted(model, x, labels, k, eps, eps_step):\n","    model.eval()\n","    ce_loss = torch.nn.CrossEntropyLoss()\n","    adv_x = x.clone().detach() # [B, C, H, W]\n","    adv_x.requires_grad_(True)\n","\n","    # first take random step:\n","    # need to generate a tensor of same size as x but with range [-1,1]\n","    # then normalize and multiply to eps and apply to x\n","    delta = torch.randn_like(x) # [B, C, H, W]\n","    # tkae l2 norm for each image\n","    delta_norms = torch.norm(delta.view(x.size(0), -1), p = 2, dim = 1) # [B, ]\n","    # normalize delta of each image\n","    delta = delta/ (delta_norms.view(-1,1,1,1) + 1e-10)\n","    # scale to step size\n","    delta = delta * eps\n","    # we know that it will stay within limits becuase th emost it can move is eps_step < eps\n","    # so no need to project back onto bubble\n","    adv_x = torch.clamp(x + delta, min = 0.0 , max = 1.0).detach().requires_grad_()\n","\n","    for _ in range(k):\n","        adv_x.requires_grad_(True)\n","        model.zero_grad()\n","        output = model(adv_x) # size = [B, 10]\n","        '''we are given x that can be multiple images [B,C,H,W] '''\n","        '''batch_size = B = number of images in batch'''\n","        '''1. Find New adv_x\n","           2. Project Onto x bubble'''\n","        batch_size = x.size(0)\n","        # TODO: Calculate the loss\n","        loss = ce_loss(output, labels )\n","        loss.backward()\n","\n","        '''1. Find New Adv_X'''\n","        # TODO: compute the adv_x\n","        grad = adv_x.grad.data # [B, C, H, W] --> each value represnets gardient at pixel (H,W) of color channel C of picture B\n","        # reshape grad using view() to [B, C*H*W] so each row includes all pixels for an image\n","        # calculate l2 norm\n","        # resize to [B,1,1,1] to do computation with grad\n","        grad_norms = torch.norm(grad.view(batch_size, -1), p = 2, dim =1) # [B]\n","        grad_norms = grad_norms.view(batch_size,1,1,1) # [B,1,1,1]\n","        grad = grad/ (grad_norms +1e-10) #[B,C,H,W] --> back to gradient of each pixel-channel, add 1e-10 for divide by zero\n","        # increment adv_x by grad\n","        adv_x = adv_x + eps_step * grad\n","\n","        '''2. Project Onto x Bubble'''\n","        # find delta, clamp with eps, project delta to the l2 ball\n","        '''x_proj = x + epsilong * ( delta )/ (max ( l2 norm of delta, epsilon  ))'''\n","        delta = adv_x - x #[B,C,H,W]\n","        # get l2 norms of delta\n","        delta_norms = torch.norm(delta.view(batch_size,-1), p = 2, dim = 1)\n","        # get tensor of ratios between epsilon and l2 norms\n","        factor = eps/ delta_norms\n","        # if l2 norm is greater than eps, we wnat to cap at eps (overall factor = 1), else we use l2 (overall factor = eps/delta_nroms)\n","        # factor = min(eps/delta_norms, eps/eps)\n","        factor = torch.min(factor,torch.ones_like(factor)) #[B, C, H, W]\n","\n","        delta = delta * factor.view(-1,1,1,1)\n","\n","        adv_x = torch.clamp(x + delta, min = 0.0 , max = 1.0).detach().requires_grad_()\n","\n","        # HINT: https://github.com/Harry24k/adversarial-attacks-pytorch/blob/master/torchattacks/attacks/pgdl2.py <-- THANKS :D\n","\n","    return adv_x"]},{"cell_type":"markdown","metadata":{"id":"0Mja_AB4RykO"},"source":["# Evaluate Single and Multi-Norm Robust Accuracy\n","\n","In this section, we evaluate the model on the Linf and L2 attacks as well as union accuracy."]},{"cell_type":"code","execution_count":8,"metadata":{"id":"DHj92DsCns3q","executionInfo":{"status":"ok","timestamp":1758323846382,"user_tz":300,"elapsed":3,"user":{"displayName":"Lucas Liu","userId":"15281844812703134281"}}},"outputs":[],"source":["def test_model_on_single_attack(model, attack='pgd_linf', eps=0.1, k = 10):\n","    model.eval()\n","    tot_test, tot_acc = 0.0, 0.0\n","    for batch_idx, (x_batch, y_batch) in tqdm(enumerate(test_loader), total=len(test_loader), desc=\"Evaluating\"):\n","        x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n","        #print('On batch: ', batch_idx)\n","        if attack == 'pgd_linf':\n","            # TODO: get x_adv untargeted pgd linf with eps, and eps_step=eps/4\n","            adv_x = pgd_linf_untargeted(model,x_batch,y_batch,k,eps = eps,eps_step= eps/4 )\n","            #\n","            with torch.no_grad():\n","                logits = model(adv_x)\n","                predicts = logits.argmax(dim =1 )\n","\n","\n","        elif attack == 'pgd_l2':\n","            # TODO: get x_adv untargeted pgd l2 with eps, and eps_step=eps/4\n","            adv_x = pgd_l2_untargeted(model,x_batch,y_batch,k,eps = eps,eps_step= eps/4)\n","            with torch.no_grad():\n","                logits = model(adv_x)\n","                predicts = logits.argmax(dim=1)\n","        else:\n","            pass\n","\n","        # get the testing accuracy and update tot_test and tot_acc\n","        '''num got right = sum(predicts = y_batch)'''\n","        tot_acc += (predicts == y_batch).sum().item()\n","        '''num total'''\n","        tot_test += y_batch.size(0)\n","        #print('Accuracy So Far: %.5lf' % (tot_acc/tot_test), f'on {attack} attack with eps = {eps}')\n","\n","    print('Robust accuracy %.5lf' % (tot_acc/tot_test), f'on {attack} attack with eps = {eps}')"]},{"cell_type":"markdown","metadata":{"id":"ZPMdfEhtR3zm"},"source":["## Single-Norm Robust Accuracy"]},{"cell_type":"markdown","source":["####L_inf Adverserial Attack"],"metadata":{"id":"Nl-n-efQuM1q"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"FvbTdgSfns3q"},"outputs":[],"source":["# Evaluate on Linf attack with different models with eps = 8/255\n","model.load_state_dict(torch.load('models/pretr_Linf.pth', map_location=torch.device('cpu')))\n","# Evaluate on Linf attack with model 1 with eps = 8/255\n","test_model_on_single_attack(model=model, attack = 'pgd_linf', eps = 8/225)\n","'''Robust accuracy 0.46400 on pgd_linf attack with eps = 0.035555555555555556'''"]},{"cell_type":"code","source":["\n","model.load_state_dict(torch.load('models/pretr_L2.pth', map_location=torch.device('cpu')))\n","# Evaluate on Linf attack with model 2 with eps = 8/255\n","test_model_on_single_attack(model=model, attack = 'pgd_linf', eps = 8/225)\n","''' Robust accuracy 0.23940 on pgd_linf attack with eps = 0.035555555555555556'''\n"],"metadata":{"id":"swXhFbfmqr5Z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.load_state_dict(torch.load('models/pretr_RAMP.pth', map_location=torch.device('cpu')))\n","# Evaluate on Linf attack with model 3 with eps = 8/255\n","test_model_on_single_attack(model=model, attack = 'pgd_linf', eps = 8/225)\n","'''Robust accuracy 0.44610 on pgd_linf attack with eps = 0.0355'''"],"metadata":{"id":"9W-b0hQ4qtc1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### L2 Adverserial ATtack"],"metadata":{"id":"_kVvBps4uR7P"}},{"cell_type":"code","source":["# Evaluate on L2 attack with different models with eps = 0.75\n","model.load_state_dict(torch.load('models/pretr_Linf.pth', map_location=torch.device('cpu')))\n","# Evaluate on Linf attack with model 1 with eps = 0.75\n","test_model_on_single_attack(model=model, attack = 'pgd_l2', eps = 0.75)\n","'''Robust accuracy 0.49990 on pgd_l2 attack with eps = 0.75'''"],"metadata":{"id":"IJGtvGA1uVEX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","model.load_state_dict(torch.load('models/pretr_L2.pth', map_location=torch.device('cpu')))\n","# Evaluate on Linf attack with model 2 with eps = 0.75\n","test_model_on_single_attack(model=model, attack = 'pgd_l2', eps = 0.75)\n","'''Robust accuracy 0.55520 on pgd_l2 attack with eps = 0.75'''"],"metadata":{"id":"gi5RyZF_uYkh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.load_state_dict(torch.load('models/pretr_RAMP.pth', map_location=torch.device('cpu')))\n","# Evaluate on Linf attack with model 3 with eps = 0.75\n","test_model_on_single_attack(model=model, attack = 'pgd_l2', eps = 0.75)\n","'''Robust accuracy 0.60250 on pgd_l2 attack with eps = 0.75'''"],"metadata":{"id":"j-pRyrf3u6pC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eJOF_gcPns3q"},"source":["## Multi-Norm Robust Accuracy"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"exEptJRfns3q"},"outputs":[],"source":["def test_model_on_multi_attacks(model, eps_linf=8./255., eps_l2=0.75):\n","    k = 10\n","    model.eval()\n","    tot_test, tot_acc = 0.0, 0.0\n","    for batch_idx, (x_batch, y_batch) in tqdm(enumerate(test_loader), total=len(test_loader), desc=\"Evaluating\"):\n","        #print(\"On batch: \", batch_idx)\n","        x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n","        # TODO: get x_adv_linf and x_adv_l2 untargeted pgd linf and l2 with eps, and eps_step=eps/4\n","        x_adv_linf = pgd_linf_untargeted(model, x_batch, y_batch, k, eps_linf,eps_linf/4)\n","        x_adv_l2 = pgd_l2_untargeted(model, x_batch, y_batch, k, eps_l2, eps_l2/4)\n","\n","        ## calculate union accuracy: correct only if both attacks are correct\n","\n","        out = model(x_adv_linf)\n","        pred_linf = torch.max(out, dim=1)[1]\n","        out = model(x_adv_l2)\n","        pred_l2 = torch.max(out, dim=1)[1]\n","\n","        # TODO: get the testing accuracy with multi-norm robustness and update tot_test and tot_acc\n","        tot_acc += ((pred_linf == y_batch) & (pred_l2 == y_batch)).sum().item()\n","        tot_test += y_batch.size(0)\n","        #print('accuracy so far %.5lf' % (tot_acc/tot_test), f'on multi attacks')\n","\n","    print('Robust accuracy %.5lf' % (tot_acc/tot_test), f'on multi attacks')"]},{"cell_type":"code","source":["# Evaluate on L2 attack with different models with eps_linf = 8./255, eps_l2 = 0.75\n","model.load_state_dict(torch.load('models/pretr_Linf.pth'))\n","# Evaluate on multi attacks with model 1\n","test_model_on_multi_attacks(model)\n","'''Robust accuracy 0.47840 on multi attack'''\n"],"metadata":{"id":"i_7C8DPgq69q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","model.load_state_dict(torch.load('models/pretr_L2.pth'))\n","# Evaluate on multi attacks with model 2\n","test_model_on_multi_attacks(model)\n","'''Robust accuracy 0.30850 on multi attacks'''\n"],"metadata":{"id":"03WKbUIMq7oe"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"J8jOsQMjns3q"},"outputs":[],"source":["model.load_state_dict(torch.load('models/pretr_RAMP.pth'))\n","# Evaluate on multi attacks with model 3\n","test_model_on_multi_attacks(model)\n","'''Robust accuracy 0.49750 on multi attacks'''\n"]},{"cell_type":"markdown","source":["## Normal Accuracy"],"metadata":{"id":"1rqgjdBeAQQl"}},{"cell_type":"code","source":["def test_model_standard(model):\n","    model.eval()\n","    tot_test, tot_acc = 0.0, 0.0\n","    for batch_idx, (x_batch, y_batch) in tqdm(enumerate(test_loader), total=len(test_loader), desc=\"Evaluating Standard\"):\n","        x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n","        with torch.no_grad():\n","            # predict\n","            logits = model(x_batch)\n","            # find highest prob\n","            predicts = logits.argmax(dim=1)\n","\n","\n","        tot_acc += (predicts == y_batch).sum().item()\n","        tot_test += y_batch.size(0)\n","\n","    acc = tot_acc / tot_test\n","    print(f'Standard accuracy {acc:.5f}')\n","    return acc"],"metadata":{"id":"S1789VvxATGt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# get normal accuracy of model\n","model.load_state_dict(torch.load('models/pretr_Linf.pth', map_location=torch.device('cpu')))\n","test_model_standard(model)\n","#0.828"],"metadata":{"id":"NsnQtW-rAoVI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.load_state_dict(torch.load('models/pretr_L2.pth', map_location=torch.device('cpu')))\n","test_model_standard(model)"],"metadata":{"id":"6R1CYKtRBy6y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.load_state_dict(torch.load('models/pretr_RAMP.pth', map_location=torch.device('cpu')))\n","test_model_standard(model)"],"metadata":{"id":"NVaVR3tmBzLx"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[],"gpuType":"T4","toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.0"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}